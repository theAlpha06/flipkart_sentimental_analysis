{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6fa822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c48de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d033f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./reviews_badminton/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9526a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8518, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcb4236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=7ee3074f-2dea-4049-8ac6-23c55d202edd style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('7ee3074f-2dea-4049-8ac6-23c55d202edd').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now rising which is a bad sign. 800-850 was an affordable price, especially when we play everyday. So kindly help us out in terms of the price. Thank You.READ MORE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside cover was Yonex Ad inside was a cheapest....  Sad to hear this.READ MORE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in new box. It's not a original yonex product. Don't buy.flipkart platform is chosen to fraud the buyers.READ MORE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the corks like not as before 3 to 5 years back.. I am using MAVIS 350 for more than 15 years quality of corks was very very good at that times, but now I am not getting the quality corks as like before, rate of corks also too much now, I am  very sorry to say like this, but in my experience , my Statment is very true to   my knowledgeREAD MORE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn't understand.. Wat is d advantage of buying dis frm flipkrtREAD MORE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccda1aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8518 entries, 0 to 8517\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8518 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3228b96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=47cc621e-9005-4b94-8970-d26afdceb9d9 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('47cc621e-9005-4b94-8970-d26afdceb9d9').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8508.000000</td>\n",
       "      <td>8508.000000</td>\n",
       "      <td>8518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.391396</td>\n",
       "      <td>0.121768</td>\n",
       "      <td>4.181028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.613909</td>\n",
       "      <td>3.248022</td>\n",
       "      <td>1.262200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "          Up Votes   Down Votes      Ratings\n",
       "count  8508.000000  8508.000000  8518.000000\n",
       "mean      0.391396     0.121768     4.181028\n",
       "std      11.613909     3.248022     1.262200\n",
       "min       0.000000     0.000000     1.000000\n",
       "25%       0.000000     0.000000     4.000000\n",
       "50%       0.000000     0.000000     5.000000\n",
       "75%       0.000000     0.000000     5.000000\n",
       "max     889.000000   219.000000     5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eff1b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230310b4",
   "metadata": {},
   "source": [
    "### Fill  the null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc26059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Up Votes'].fillna(df['Up Votes'].mean(), inplace=True)\n",
    "df['Down Votes'].fillna(df['Down Votes'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41748763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviewer Name'].fillna(df['Reviewer Name'].mode()[0], inplace=True)\n",
    "df['Review Title'].fillna(df['Review Title'].mode()[0], inplace=True)\n",
    "df['Place of Review'].fillna(df['Place of Review'].mode()[0], inplace=True)\n",
    "df['Month'].fillna(df['Month'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968f0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 'Review text' column, you can fill the null values with a string indicating no review was given\n",
    "df['Review text'].fillna('No review text given', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b311bde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name      0\n",
       "Review Title       0\n",
       "Place of Review    0\n",
       "Up Votes           0\n",
       "Down Votes         0\n",
       "Month              0\n",
       "Review text        0\n",
       "Ratings            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8e83a",
   "metadata": {},
   "source": [
    "## Labeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428249aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to create a label named as Sentiment with the help of rating column \n",
    "def label_data(rating):\n",
    "    if rating >= 3:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "df['Sentiment'] = df['Ratings'].apply(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a17ec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    7441\n",
       "negative    1077\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076a56d",
   "metadata": {},
   "source": [
    "### Mapping of categorical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e720c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'positive': 1, 'negative': 0}\n",
    "df['Sentiment_num'] = df['Sentiment'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db9640e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=211d7dc8-1d37-40b3-88cd-7c296ddbcc25 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('211d7dc8-1d37-40b3-88cd-7c296ddbcc25').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now rising which is a bad sign. 800-850 was an affordable price, especially when we play everyday. So kindly help us out in terms of the price. Thank You.READ MORE</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside cover was Yonex Ad inside was a cheapest....  Sad to hear this.READ MORE</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in new box. It's not a original yonex product. Don't buy.flipkart platform is chosen to fraud the buyers.READ MORE</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oct 2020</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the corks like not as before 3 to 5 years back.. I am using MAVIS 350 for more than 15 years quality of corks was very very good at that times, but now I am not getting the quality corks as like before, rate of corks also too much now, I am  very sorry to say like this, but in my experience , my Statment is very true to   my knowledgeREAD MORE</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>Certified Buyer, Bengaluru</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn't understand.. Wat is d advantage of buying dis frm flipkrtREAD MORE</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0  Oct 2020   \n",
       "4   Certified Buyer, Bengaluru     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings Sentiment  \\\n",
       "0  Nice product, good quality, but price is now r...        4  positive   \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  negative   \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  negative   \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  positive   \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  negative   \n",
       "\n",
       "   Sentiment_num  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b1fa3",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce0b4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[\"Review text\"]\n",
    "y=df[\"Sentiment_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0ac7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Nice product, good quality, but price is now r...\n",
       "1    They didn't supplied Yonex Mavis 350. Outside ...\n",
       "2    Worst product. Damaged shuttlecocks packed in ...\n",
       "3    Quite O. K. , but nowadays  the quality of the...\n",
       "4    Over pricedJust â?¹620 ..from retailer.I didn'...\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd86adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: Sentiment_num, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b38ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9b37900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6814,), (1704,), (6814,), (1704,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d1b53",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00327b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a029b2",
   "metadata": {},
   "source": [
    "###  Cleaning of the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c294ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Text Cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    \n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "X_train= X_train.apply(clean_text)\n",
    "\n",
    "# 2. Text Normalization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "X_train = X_train.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00e8d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6289                                     nice shuttleread\n",
       "549     product good received stock 3 4 month befor ma...\n",
       "4707    excellent service got one day even remote loca...\n",
       "764                                  good high price read\n",
       "6861                    2 damaged shuttle 6 satisfiedread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd0c926a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497    Fast deliveryOriginal productReasonable priceR...\n",
       "5257               working well in out door gameREAD MORE\n",
       "2571    Its value for money and most importantly it's ...\n",
       "1084                                    HorribleREAD MORE\n",
       "856                                         GoogREAD MORE\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1118a9",
   "metadata": {},
   "source": [
    "## Numerical Feature Extraction\n",
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "799e333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=clean_text, max_features=5000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac82eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 2782\n",
      "Type of train features: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of input data: (6814, 2782)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique words:\", len(vectorizer.vocabulary_))\n",
    "\n",
    "print(\"Type of train features:\", type(X_train_bow))\n",
    "\n",
    "print(\"Shape of input data:\", X_train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e53f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91d75154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "48 Bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(type(X_train_bow))\n",
    "print(getsizeof(X_train_bow), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fa27cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "151652512 Bytes\n"
     ]
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(type(X_train_bow.toarray()))\n",
    "print(getsizeof(X_train_bow.toarray()), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89a4b0",
   "metadata": {},
   "source": [
    "### Preprocess the X_test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77c3b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497    Fast deliveryOriginal productReasonable priceR...\n",
       "5257               working well in out door gameREAD MORE\n",
       "2571    Its value for money and most importantly it's ...\n",
       "1084                                    HorribleREAD MORE\n",
       "856                                         GoogREAD MORE\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "311b24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.apply(clean_text)\n",
    "\n",
    "X_test = X_test.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ea0b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497    fast deliveryoriginal productreasonable priceread\n",
       "5257                           working well door gameread\n",
       "2571                 value money importantly originalread\n",
       "1084                                         horribleread\n",
       "856                                              googread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fa66579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9767430d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1704x2782 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5564 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb8826",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7435ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbf83ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4456998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9219483568075117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.45      0.58       199\n",
      "           1       0.93      0.98      0.96      1505\n",
      "\n",
      "    accuracy                           0.92      1704\n",
      "   macro avg       0.86      0.72      0.77      1704\n",
      "weighted avg       0.91      0.92      0.91      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a442a",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1559bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c7bed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = nb.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a9959c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92018779342723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.48      0.59       199\n",
      "           1       0.93      0.98      0.96      1505\n",
      "\n",
      "    accuracy                           0.92      1704\n",
      "   macro avg       0.84      0.73      0.77      1704\n",
      "weighted avg       0.91      0.92      0.91      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e419240",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edcdffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc=svm.SVC()\n",
    "svc.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77344d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=svc.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c913991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497    1\n",
       "5257    1\n",
       "2571    1\n",
       "1084    1\n",
       "856     1\n",
       "Name: Sentiment_num, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b417c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85cfbb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909037558685446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.31      0.44       199\n",
      "           1       0.92      0.99      0.95      1505\n",
      "\n",
      "    accuracy                           0.91      1704\n",
      "   macro avg       0.85      0.65      0.70      1704\n",
      "weighted avg       0.90      0.91      0.89      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44d4af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Memory\n",
    "\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57c8e41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6814,), (6814,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5b49b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "CPU times: total: 5.73 s\n",
      "Wall time: 6.7 s\n",
      "Score on Test Data:  0.92018779342723\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "CPU times: total: 7min 26s\n",
      "Wall time: 7min 28s\n",
      "Score on Test Data:  0.9078638497652582\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 23.3 s\n",
      "Wall time: 23.9 s\n",
      "Score on Test Data:  0.9125586854460094\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 3min 27s\n",
      "Wall time: 3min 30s\n",
      "Score on Test Data:  0.9213615023474179\n"
     ]
    }
   ],
   "source": [
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ], memory=memory),\n",
    "    'svc': Pipeline([\n",
    "    ('vectorization', CountVectorizer()),\n",
    "    ('classifier', SVC(kernel='linear')),\n",
    "    ],memory=memory)\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "    'svc':[\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_df': [0.5, 0.75, 1.0],\n",
    "            'vectorization__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each algorithm\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4b62339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 25.1 ms\n",
      "Accuracy Score 0.92018779342723\n",
      "Model Size: 160918 Bytes\n",
      "********** logistic_regression **********\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.6 ms\n",
      "Accuracy Score 0.9078638497652582\n",
      "Model Size: 94217 Bytes\n",
      "********** decision_tree **********\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.5 ms\n",
      "Accuracy Score 0.9125586854460094\n",
      "Model Size: 83800 Bytes\n",
      "********** svc **********\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 156 ms\n",
      "Accuracy Score 0.9213615023474179\n",
      "Model Size: 180581 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    \n",
    "    joblib.dump(model, f'best_models/{name}.pkl')\n",
    "    model = joblib.load(f'best_models/{name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"Accuracy Score\", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc02ec",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8c814f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfVectorizer()\n",
    "X_train_idf = tfidfconverter.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c8543d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_idf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddcac48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idf=tfidfconverter.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8ac2d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a15ba7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_idf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07dc9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_idf=classifier.predict(X_test_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d6d93bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184272300469484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.40      0.53       199\n",
      "           1       0.93      0.99      0.96      1505\n",
      "\n",
      "    accuracy                           0.92      1704\n",
      "   macro avg       0.87      0.69      0.74      1704\n",
      "weighted avg       0.91      0.92      0.91      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_idf))\n",
    "\n",
    "print(classification_report(y_test, y_pred_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c48317",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eb409c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184272300469484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.43      0.55       199\n",
      "           1       0.93      0.98      0.96      1505\n",
      "\n",
      "    accuracy                           0.92      1704\n",
      "   macro avg       0.85      0.71      0.75      1704\n",
      "weighted avg       0.91      0.92      0.91      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train_idf,y_train)\n",
    "y_pred_idf=svc.predict(X_test_idf)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_idf))\n",
    "\n",
    "print(classification_report(y_test, y_pred_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043011e",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1dc289f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9019953051643192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.19      0.31       199\n",
      "           1       0.90      1.00      0.95      1505\n",
      "\n",
      "    accuracy                           0.90      1704\n",
      "   macro avg       0.89      0.59      0.63      1704\n",
      "weighted avg       0.90      0.90      0.87      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb.fit(X_train_idf, y_train)\n",
    "\n",
    "y_pred_idf=nb.predict(X_test_idf)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_idf))\n",
    "\n",
    "print(classification_report(y_test, y_pred_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00e95e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "CPU times: total: 5.81 s\n",
      "Wall time: 6.87 s\n",
      "Score on Test Data:  0.9160798122065728\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "CPU times: total: 5min 37s\n",
      "Wall time: 5min 38s\n",
      "Score on Test Data:  0.892018779342723\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 3min 29s\n",
      "Wall time: 3min 33s\n",
      "Score on Test Data:  0.920774647887324\n"
     ]
    }
   ],
   "source": [
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization',  TfidfVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization',  TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'svc': Pipeline([\n",
    "    ('vectorization',  TfidfVectorizer()),\n",
    "    ('classifier', SVC(kernel='linear')),\n",
    "    ],memory=memory)\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [ TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [ TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    ],\n",
    "    'svc':[\n",
    "        {\n",
    "            'vectorization': [ TfidfVectorizer()],\n",
    "            'vectorization__max_df': [0.5, 0.75, 1.0],\n",
    "            'vectorization__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each algorithm\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2cdadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.6 ms\n",
      "Accuracy Score 0.9160798122065728\n",
      "Model Size: 99578 Bytes\n",
      "********** logistic_regression **********\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.6 ms\n",
      "Accuracy Score 0.892018779342723\n",
      "Model Size: 139133 Bytes\n",
      "********** svc **********\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 281 ms\n",
      "Accuracy Score 0.920774647887324\n",
      "Model Size: 819657 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    model_name=f\"{name}_tfidf\"\n",
    "    joblib.dump(model, f'best_models/{model_name}.pkl')\n",
    "    model = joblib.load(f'best_models/{model_name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"Accuracy Score\", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{model_name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad49054",
   "metadata": {},
   "source": [
    "## Converting Text to Numerical vectors - Word2Vec Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d54522",
   "metadata": {},
   "source": [
    "Step 1 - Import Word2Vec module from gensim.models\n",
    "\n",
    "\n",
    "Step 2 - Convert the sentences to the List of Words (i.e. List of Tokens)\n",
    "\n",
    "\n",
    "Step 3 - Use Word2Vec to learn numerical vectors for each unique words. Word2Vec uses the list of tokens and generate 300Dimensional numerical vector for each unique word.\n",
    "\n",
    "\n",
    "Step 4 - Convert the word vectors to document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8042c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00f99986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54558342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6814,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "977d44f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6289                                     nice shuttleread\n",
       "549     product good received stock 3 4 month befor ma...\n",
       "4707    excellent service got one day even remote loca...\n",
       "764                                  good high price read\n",
       "6861                    2 damaged shuttle 6 satisfiedread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3fb483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "X_train_tokenised_sentences = X_train.apply(lambda sent : sent.split())\n",
    "model = Word2Vec(list(X_train), vector_size=300, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75b6e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 300)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of vectors learned by the model\n",
    "\n",
    "print(model.wv.__getitem__(model.wv.index_to_key).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba4821d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vec(doc, keyed_vectors):\n",
    "    \"\"\"Remove out-of-vocabulary words. Create document vectors by averaging word vectors.\"\"\"\n",
    "    vocab_tokens = [word for word in doc if word in keyed_vectors.index_to_key]\n",
    "    if len(vocab_tokens) == 0:\n",
    "        # Return a vector of zeros if no words are in the vocabulary\n",
    "        return np.zeros(keyed_vectors.vector_size)\n",
    "    else:\n",
    "        return np.mean(keyed_vectors.__getitem__(vocab_tokens), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49f4fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6814/6814 [00:00<00:00, 11640.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "X_train_doc_vector= X_train_tokenised_sentences.progress_apply(lambda x : document_vec(x, model.wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e3c4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = list(X_train_doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bb0212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scaling(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    return(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bec6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v=scaling(X_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d65a0d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497    fast deliveryoriginal productreasonable priceread\n",
       "5257                           working well door gameread\n",
       "2571                 value money importantly originalread\n",
       "1084                                         horribleread\n",
       "856                                              googread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tokenised_sentences = X_test.apply(lambda sent : sent.split())\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aaba5ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1704/1704 [00:00<00:00, 46071.05it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_doc_vector = X_test_tokenised_sentences.progress_apply(lambda x : document_vec(x, model.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "915128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w2v = list(X_test_doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57827e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w2v=scaling(X_test_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5c137",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8aaddcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8832159624413145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       199\n",
      "           1       0.88      1.00      0.94      1505\n",
      "\n",
      "    accuracy                           0.88      1704\n",
      "   macro avg       0.44      0.50      0.47      1704\n",
      "weighted avg       0.78      0.88      0.83      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train_w2v,y_train)\n",
    "\n",
    "y_pred_w2v=classifier.predict(X_test_w2v)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_w2v))\n",
    "\n",
    "print(classification_report(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff2ad2",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25f25783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8802816901408451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.02      0.04       199\n",
      "           1       0.88      0.99      0.94      1505\n",
      "\n",
      "    accuracy                           0.88      1704\n",
      "   macro avg       0.60      0.51      0.49      1704\n",
      "weighted avg       0.82      0.88      0.83      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train_w2v,y_train)\n",
    "\n",
    "y_pred_w2v=clf.predict(X_test_w2v)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_w2v))\n",
    "\n",
    "print(classification_report(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ee348",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39bcd075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8832159624413145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       199\n",
      "           1       0.88      1.00      0.94      1505\n",
      "\n",
      "    accuracy                           0.88      1704\n",
      "   macro avg       0.44      0.50      0.47      1704\n",
      "weighted avg       0.78      0.88      0.83      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train_w2v,y_train)\n",
    "y_pred_w2v=svc.predict(X_test_w2v)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_w2v))\n",
    "\n",
    "print(classification_report(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "763ee9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6814,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cef3108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6814,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd050743",
   "metadata": {},
   "source": [
    "## Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61f85670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, size=100, window=5, min_count=1, workers=4):\n",
    "        self.size = size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        tokenised_sentences = [sent.split() for sent in X]\n",
    "        self.model = Word2Vec(tokenised_sentences, vector_size=self.size, window=self.window, min_count=self.min_count, workers=self.workers)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        tokenised_sentences = [sent.split() for sent in X]\n",
    "        return np.array([self.document_vector(words) for words in tokenised_sentences])\n",
    "\n",
    "    def document_vector(self, words):\n",
    "        vocab_tokens = [word for word in words if word in self.model.wv.index_to_key]\n",
    "        if len(vocab_tokens) == 0:\n",
    "            return np.zeros(self.model.vector_size)\n",
    "        else:\n",
    "            return np.mean(self.model.wv.__getitem__(vocab_tokens), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7bcee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 1min 51s\n",
      "Wall time: 1min 45s\n",
      "Score on Test Data:  0.8832159624413145\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 9min 25s\n",
      "Wall time: 11min 23s\n",
      "Score on Test Data:  0.8832159624413145\n"
     ]
    }
   ],
   "source": [
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization',  Word2VecVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    \n",
    "\n",
    "    \n",
    "    'svc': Pipeline([\n",
    "        ('vectorization',  Word2VecVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization__size': [100, 200],\n",
    "            'vectorization__window': [5, 10],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l2'], \n",
    "            'classifier__solver': ['lbfgs'],\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \n",
    "    'svc':[\n",
    "        {\n",
    "            'vectorization__size': [100,200],\n",
    "            'vectorization__window': [5, 10],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "779eb012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** logistic_regression **********\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 425 ms\n",
      "Accuracy Score 0.8832159624413145\n",
      "Model Size: 2341786 Bytes\n",
      "********** svc **********\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 1.08 s\n",
      "Accuracy Score 0.8832159624413145\n",
      "Model Size: 3817702 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    model_name=f\"{name}_w2v\"\n",
    "    joblib.dump(model, f'best_models/{model_name}.pkl')\n",
    "    model = joblib.load(f'best_models/{model_name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"Accuracy Score\", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{model_name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a0946",
   "metadata": {},
   "source": [
    "### GloVe Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f290fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e659606",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "828f0529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6289                                     nice shuttleread\n",
       "549     product good received stock 3 4 month befor ma...\n",
       "4707    excellent service got one day even remote loca...\n",
       "764                                  good high price read\n",
       "6861                    2 damaged shuttle 6 satisfiedread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a3b3a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6814/6814 [05:14<00:00, 21.70it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_pretrained_glove=X_train_tokenised_sentences.progress_apply(lambda x : document_vec(x, wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfe27956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove = list(X_train_pretrained_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef3ff998",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove=scaling(X_train_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "806876eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1704/1704 [01:21<00:00, 20.97it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_pretrained_glove = X_test_tokenised_sentences.progress_apply(lambda x : document_vec(x, wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fda554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_glove = list(X_test_pretrained_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d688833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_glove=scaling(X_test_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37fbadb",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "51f6393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9043427230046949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.43      0.51       199\n",
      "           1       0.93      0.97      0.95      1505\n",
      "\n",
      "    accuracy                           0.90      1704\n",
      "   macro avg       0.78      0.70      0.73      1704\n",
      "weighted avg       0.89      0.90      0.90      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_glove, y_train)\n",
    "\n",
    "y_test_pred = classifier.predict(X_test_glove)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e4952",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39397d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585093896713615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.86      0.33       199\n",
      "           1       0.97      0.55      0.70      1505\n",
      "\n",
      "    accuracy                           0.59      1704\n",
      "   macro avg       0.59      0.71      0.51      1704\n",
      "weighted avg       0.88      0.59      0.66      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_glove, y_train)\n",
    "\n",
    "y_pred_glove = gnb.predict(X_test_glove)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_glove))\n",
    "\n",
    "print(classification_report(y_test, y_pred_glove))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8dd666",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b1335d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9131455399061033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.41      0.52       199\n",
      "           1       0.93      0.98      0.95      1505\n",
      "\n",
      "    accuracy                           0.91      1704\n",
      "   macro avg       0.83      0.69      0.74      1704\n",
      "weighted avg       0.90      0.91      0.90      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_glove, y_train)\n",
    "\n",
    "y_pred_glove = svc.predict(X_test_glove)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_glove))\n",
    "\n",
    "print(classification_report(y_test, y_pred_glove))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2778c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "class GloVeVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, glove_file='glove.6B.100d.txt'):\n",
    "        self.glove_file = glove_file\n",
    "        self.word_vectors = self.load_glove_model()\n",
    "\n",
    "    def load_glove_model(self):\n",
    "        word2vec_output_file = self.glove_file + '.word2vec'\n",
    "        glove2word2vec(self.glove_file, word2vec_output_file)\n",
    "        return KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.document_vector(doc) for doc in X])\n",
    "\n",
    "    def document_vector(self, doc):\n",
    "        words = self.preprocess_text(doc)\n",
    "        return np.mean([self.word_vectors[w] for w in words if w in self.word_vectors] or [np.zeros(self.word_vectors.vector_size)], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da8bbe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "CPU times: total: 11.6 s\n",
      "Wall time: 14.2 s\n",
      "Score on Test Data:  0.9160798122065728\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 1min 44s\n",
      "Wall time: 1min 29s\n",
      "Score on Test Data:  0.8832159624413145\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 8min 4s\n",
      "Wall time: 9min 10s\n",
      "Score on Test Data:  0.8832159624413145\n"
     ]
    }
   ],
   "source": [
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    \n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization',  Word2VecVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization',  Word2VecVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    \n",
    "    'svc': Pipeline([\n",
    "        ('vectorization',  Word2VecVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "     'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [ Word2VecVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000, 5000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization__size': [100, 200],\n",
    "            'vectorization__window': [5, 10],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l2'], \n",
    "            'classifier__solver': ['lbfgs'],\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \n",
    "    'svc':[\n",
    "        {\n",
    "            'vectorization__size': [100,200],\n",
    "            'vectorization__window': [5, 10],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28e95a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 358 ms\n",
      "Accuracy Score 0.9160798122065728\n",
      "Model Size: 99578 Bytes\n",
      "********** logistic_regression **********\n",
      "CPU times: total: 375 ms\n",
      "Wall time: 429 ms\n",
      "Accuracy Score 0.8832159624413145\n",
      "Model Size: 2341786 Bytes\n",
      "********** svc **********\n",
      "CPU times: total: 1.19 s\n",
      "Wall time: 1.42 s\n",
      "Accuracy Score 0.8832159624413145\n",
      "Model Size: 3817814 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    model_name=f\"{name}_glove\"\n",
    "    joblib.dump(model, f'best_models/{model_name}.pkl')\n",
    "    model = joblib.load(f'best_models/{model_name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"Accuracy Score\", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{model_name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34340bf6",
   "metadata": {},
   "source": [
    "##  BERT for Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0d286f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a66ced9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6814/6814 [04:02<00:00, 28.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6289                                     nice shuttleread\n",
       "549     product good received stock 3 4 month befor ma...\n",
       "4707    excellent service got one day even remote loca...\n",
       "764                                  good high price read\n",
       "6861                    2 damaged shuttle 6 satisfiedread\n",
       "Name: Review text, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pretrained_bert = X_train.progress_apply(model.encode)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5d69a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert_pretrained = list(X_train_pretrained_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ebef7768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1704/1704 [01:01<00:00, 27.76it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_pretrained_bert = X_test.progress_apply(model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1cc35c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bert_pretrained = list(X_test_pretrained_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbd421",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6254e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196009389671361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.44      0.56       199\n",
      "           1       0.93      0.98      0.96      1505\n",
      "\n",
      "    accuracy                           0.92      1704\n",
      "   macro avg       0.85      0.71      0.76      1704\n",
      "weighted avg       0.91      0.92      0.91      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_bert_pretrained, y_train)\n",
    "\n",
    "y_test_pred = classifier.predict(X_test_bert_pretrained)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd20ddc",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0324cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272300469483568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.49      0.61       199\n",
      "           1       0.94      0.99      0.96      1505\n",
      "\n",
      "    accuracy                           0.93      1704\n",
      "   macro avg       0.88      0.74      0.78      1704\n",
      "weighted avg       0.92      0.93      0.92      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_bert_pretrained, y_train)\n",
    "\n",
    "y_test_pred = svc.predict(X_test_bert_pretrained)\n",
    "\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0499cc5",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16a6a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7183098591549296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.77      0.39       199\n",
      "           1       0.96      0.71      0.82      1505\n",
      "\n",
      "    accuracy                           0.72      1704\n",
      "   macro avg       0.61      0.74      0.60      1704\n",
      "weighted avg       0.88      0.72      0.77      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb.fit(X_train_bert_pretrained, y_train)\n",
    "\n",
    "y_pred=gnb.predict(X_test_bert_pretrained)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "92d0a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class BertVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.model.encode(doc) for doc in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2fff2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 2h 8min 47s\n",
      "Wall time: 1h 9min 42s\n",
      "Score on Test Data:  0.7183098591549296\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 2h 7min 50s\n",
      "Wall time: 1h 11min 51s\n",
      "Score on Test Data:  0.9242957746478874\n",
      "********** svc **********\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "CPU times: total: 2h 10min 34s\n",
      "Wall time: 1h 50min 37s\n",
      "Score on Test Data:  0.9272300469483568\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization',  BertVectorizer()),\n",
    "        ('classifier', GaussianNB())  # MultinomialNB might not work with BERT embeddings\n",
    "    ], memory=memory),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization',  BertVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory),\n",
    "    'svc': Pipeline([\n",
    "        ('vectorization',  BertVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "     'naive_bayes': [\n",
    "        {\n",
    "            'vectorization__model_name': ['all-MiniLM-L6-v2'],\n",
    "            'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]  # example parameter grid for GaussianNB\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization__model_name': ['all-MiniLM-L6-v2'],\n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['l2'], \n",
    "            'classifier__solver': ['lbfgs'],\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \n",
    "    'svc':[\n",
    "        {\n",
    "            'vectorization__model_name': ['all-MiniLM-L6-v2'],\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b9aefb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "CPU times: total: 1min 11s\n",
      "Wall time: 35.9 s\n",
      "Accuracy Score 0.7183098591549296\n",
      "Model Size: 91408178 Bytes\n",
      "********** logistic_regression **********\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 36.8 s\n",
      "Accuracy Score 0.9242957746478874\n",
      "Model Size: 91398986 Bytes\n",
      "********** svc **********\n",
      "CPU times: total: 1min 13s\n",
      "Wall time: 37.3 s\n",
      "Accuracy Score 0.9272300469483568\n",
      "Model Size: 96650310 Bytes\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    print(\"*\"*10, name, \"*\"*10)\n",
    "    model_name=f\"{name}_bert\"\n",
    "    joblib.dump(model, f'best_models/{model_name}.pkl')\n",
    "    model = joblib.load(f'best_models/{model_name}.pkl')\n",
    "    \n",
    "    %time y_test_pred = model.predict(X_test)\n",
    "    print(\"Accuracy Score\", metrics.accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    print(\"Model Size:\", os.path.getsize(f'best_models/{model_name}.pkl'), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c8c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
